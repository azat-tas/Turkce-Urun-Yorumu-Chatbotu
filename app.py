# Bu komut, aÅŸaÄŸÄ±daki kodun tamamÄ±nÄ± 'app.py' adlÄ± bir dosyaya yazar.

import streamlit as st
import google.generativeai as genai
import os
import faiss
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer
# Secrets yerine Ortam DeÄŸiÅŸkeni okumak iÃ§in os GEREKLÄ°

# --- Ã–N YÃœKLEME FONKSÄ°YONLARI (Streamlit Cache ile hÄ±zlandÄ±rma) ---
@st.cache_resource
def load_api_key_and_configure_gemini():
    """Google API AnahtarÄ±nÄ± ORTAM DEÄÄ°ÅKENÄ°NDEN yÃ¼kler ve Gemini'yi yapÄ±landÄ±rÄ±r."""
    try:
        # Ortam DeÄŸiÅŸkeninden oku ('GOOGLE_API_KEY_STREAMLIT' ismini kullanacaÄŸÄ±z)
        api_key = os.environ.get('GOOGLE_API_KEY_STREAMLIT')
        if api_key is None:
            st.error("HATA: Google API AnahtarÄ± ortam deÄŸiÅŸkeninde (GOOGLE_API_KEY_STREAMLIT) bulunamadÄ±.")
            st.stop()
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-flash-latest')
        st.success("âœ… Google API AnahtarÄ± yÃ¼klendi ve Gemini modeli yapÄ±landÄ±rÄ±ldÄ±.")
        return model
    except Exception as e:
        st.error(f"HATA: API AnahtarÄ± yÃ¼klenirken/yapÄ±landÄ±rÄ±lÄ±rken sorun oluÅŸtu: {e}")
        st.stop()

@st.cache_resource
def load_retrieval_system():
    """Embedding modelini, FAISS indeksini ve meta veriyi yÃ¼kler."""
    try:
        st.info("â³ Arama sistemi (Embedding Modeli, FAISS, Meta Veri) yÃ¼kleniyor...")
        embedding_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
        index = faiss.read_index("vektor_indeksi.faiss")
        with open("meta_veri.pkl", 'rb') as f:
            processed_data = pickle.load(f)
        st.success("âœ… Arama sistemi baÅŸarÄ±yla yÃ¼klendi.")
        return embedding_model, index, processed_data
    except FileNotFoundError:
        st.error("HATA: 'vektor_indeksi.faiss' veya 'meta_veri.pkl' dosyalarÄ± bulunamadÄ±! LÃ¼tfen bu dosyalarÄ±n Colab ortamÄ±nda olduÄŸundan emin olun.")
        st.stop()
    except Exception as e:
        st.error(f"HATA: Arama sistemi yÃ¼klenirken hata: {e}")
        st.stop()

# --- RAG FonksiyonlarÄ± ---
embedding_model = None
index = None
processed_data = None

def retrieve_contexts(query, k=5):
    if embedding_model is None or index is None or processed_data is None:
        st.error("Arama sistemi henÃ¼z yÃ¼klenmedi.")
        return []
    query_vector = embedding_model.encode([query])
    try:
        D, I = index.search(np.array(query_vector).astype('float32'), k)
        contexts = [processed_data[idx]['text'] for idx in I[0]]
        return contexts
    except Exception as e:
        st.error(f"FAISS aramasÄ± sÄ±rasÄ±nda hata: {e}")
        return []

def answer_with_rag(query, generation_model_from_cache):
    relevant_contexts = retrieve_contexts(query)
    if not relevant_contexts:
        return "Elimdeki yorumlarda bu konuyla ilgili yeterli bilgi bulamadÄ±m."
    context_str = "\n\n---\n\n".join(relevant_contexts)

    # --- PROMPT GÄ°RÄ°NTÄ°LERÄ° DÃœZELTÄ°LDÄ° ---
    prompt = f"""Sen, TÃ¼rkÃ§e Ã¼rÃ¼n yorumlarÄ±na dayanarak Ã¼rÃ¼nler hakkÄ±nda bilgi veren ve tavsiyelerde bulunan bir asistansÄ±n.
Sana verilen soruyu, YALNIZCA aÅŸaÄŸÄ±da saÄŸlanan Ã¼rÃ¼n yorumu parÃ§alarÄ±na (BaÄŸlam) dayanarak cevapla. Yorumlardaki genel kanÄ±yÄ± Ã¶zetleyebilirsin.
EÄŸer cevap, saÄŸlanan baÄŸlamda yoksa veya yorumlar yetersizse, 'Elimdeki yorumlara gÃ¶re bu konuda bir ÅŸey sÃ¶yleyemem.' de. Asla yorumlarda olmayan bilgileri uydurma.

BAÄLAM:
{context_str}

SORU:
{query}

CEVAP (Sadece yorumlara gÃ¶re):"""
    # --- ---

    try:
        response = generation_model_from_cache.generate_content(prompt)
        if not response.parts:
             return "âš ï¸ Ãœretilen cevap gÃ¼venlik filtrelerine takÄ±ldÄ±. LÃ¼tfen sorunuzu deÄŸiÅŸtirin."
        return response.text
    except Exception as e:
        st.error(f"HATA: Gemini'den cevap Ã¼retilirken sorun oluÅŸtu: {e}")
        return "Cevap Ã¼retirken bir hatayla karÅŸÄ±laÅŸtÄ±m."

# --- STREAMLIT UYGULAMA ARAYÃœZÃœ ---
st.set_page_config(page_title="ÃœrÃ¼n Yorum Chatbot'u", page_icon="ğŸ“¦")
st.title("ğŸ“¦ TÃ¼rkÃ§e ÃœrÃ¼n Yorum Chatbot'u")
st.caption("Veri Seti: Turkish Product Reviews (Alt KÃ¼me) | Model: Gemini & Sentence Transformers")

generation_model = load_api_key_and_configure_gemini()
embedding_model, index, processed_data = load_retrieval_system()

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_prompt := st.chat_input("Bir Ã¼rÃ¼n veya Ã¶zellik hakkÄ±nda soru sorun..."):
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user"):
        st.markdown(user_prompt)

    with st.chat_message("assistant"):
        with st.spinner("Yorumlar taranÄ±yor ve cevap oluÅŸturuluyor..."):
            response = answer_with_rag(user_prompt, generation_model)
        st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
